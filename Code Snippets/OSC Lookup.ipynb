{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "from astropy.table import Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sn_list_file = 'observed targets data table.csv'\n",
    "sn_col = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Github directories from the open supernova catalougue\n",
    "sne_1990_to_1999 = 'https://raw.githubusercontent.com/astrocatalogs/sne-1990-1999/master/'\n",
    "sne_2000_to_2004 = 'https://raw.githubusercontent.com/astrocatalogs/sne-2000-2004/master/'\n",
    "sne_2005_to_2009 = 'https://raw.githubusercontent.com/astrocatalogs/sne-2005-2009/master/'\n",
    "sne_2010_to_2014 = 'https://raw.githubusercontent.com/astrocatalogs/sne-2010-2014/master/'\n",
    "sne_2015_to_2019 = 'https://raw.githubusercontent.com/astrocatalogs/sne-2015-2019/master/'\n",
    "dir_list = [sne_1990_to_1999, sne_2000_to_2004, sne_2005_to_2009, sne_2010_to_2014, sne_2015_to_2019]\n",
    "\n",
    "#Create the input table of sn and an empty output table\n",
    "    #Note that the case of the supernova names in your input files matters\n",
    "sn_table = Table.read(sn_list_file, format='ascii.csv')\n",
    "data_table = Table(names = ['sn', 'z', 'RA', 'Dec'],\n",
    "                   dtype = [object, object, object, object])\n",
    "\n",
    "for row in sn_table:\n",
    "    found = False\n",
    "    \n",
    "    #First we try quicker method and assume the sn name is of the form sn####abc\n",
    "    try:\n",
    "        if 1990 <= int(row[sn_col][2:6]) <= 1999:\n",
    "            r = requests.get(sne_1990_to_1999 + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            z = data[row[sn_col]]['redshift'][0]['value']\n",
    "            \n",
    "            if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                dec = data[row[sn_col]]['dec'][0]['value']\n",
    "            \n",
    "            else:\n",
    "                ra = 'N/A'\n",
    "                dec = 'N/A'\n",
    "            \n",
    "            data_table.add_row([row[sn_col], z, ra, dec])\n",
    "            found = True\n",
    "            \n",
    "        elif 2000 <= int(row[sn_col][2:6]) <= 2004:\n",
    "            r = requests.get(sne_1990_to_1999 + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            z = data[row[sn_col]]['redshift'][0]['value']\n",
    "            \n",
    "            if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                dec = data[row[sn_col]]['dec'][0]['value']\n",
    "            \n",
    "            else:\n",
    "                ra = 'N/A'\n",
    "                dec = 'N/A'\n",
    "            \n",
    "            data_table.add_row([row[sn_col], z, ra, dec])\n",
    "            found = True\n",
    "            \n",
    "        elif 2005 <= int(row[sn_col][2:6]) <= 2009:\n",
    "            r = requests.get(sne_1990_to_1999 + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            z = data[row[sn_col]]['redshift'][0]['value']\n",
    "            \n",
    "            if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                dec = data[row[sn_col]]['dec'][0]['value']\n",
    "            \n",
    "            else:\n",
    "                ra = 'N/A'\n",
    "                dec = 'N/A'\n",
    "            \n",
    "            data_table.add_row([row[sn_col], z, ra, dec])\n",
    "            found = True\n",
    "            \n",
    "        elif 2010 <= int(row[sn_col][2:6]) <= 2014:\n",
    "            r = requests.get(sne_1990_to_1999 + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            z = data[row[sn_col]]['redshift'][0]['value']\n",
    "            \n",
    "            if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                dec = data[row[sn_col]]['dec'][0]['value']\n",
    "            \n",
    "            else:\n",
    "                ra = 'N/A'\n",
    "                dec = 'N/A'\n",
    "            \n",
    "            data_table.add_row([row[sn_col], z, ra, dec])\n",
    "            found = True\n",
    "        \n",
    "        elif 2015 <= int(row[sn_col][2:6]) <= 2019:\n",
    "            r = requests.get(sne_1990_to_1999 + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            z = data[row[sn_col]]['redshift'][0]['value']\n",
    "            \n",
    "            if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                dec = data[row[sn_col]]['dec'][0]['value']\n",
    "            \n",
    "            else:\n",
    "                ra = 'N/A'\n",
    "                dec = 'N/A'\n",
    "            \n",
    "            data_table.add_row([row[sn_col], z, ra, dec])\n",
    "            found = True\n",
    "    \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Exception for', row[sn_col])\n",
    "        print(e, '\\n', flush = True)\n",
    "    \n",
    "    #If the method above didn't work - we loop through all possibilities\n",
    "    if found == False:\n",
    "        for github_dir in dir_list:\n",
    "            r = requests.get(github_dir + urllib.parse.quote(row[sn_col]) + '.json')\n",
    "            if '404: Not Found' not in r.text:\n",
    "                data = json.loads(r.text)\n",
    "                \n",
    "                z = data[row[sn_col]]['redshift'][0]['value']\n",
    "                \n",
    "                if 'ra' in data[row[sn_col]] and 'dec' in data[row[sn_col]]:\n",
    "                    ra = data[row[sn_col]]['ra'][0]['value']\n",
    "                    dec = data[row[sn_col]]['dec'][0]['value']\n",
    "                \n",
    "                else:\n",
    "                    ra = 'N/A'\n",
    "                    dec = 'N/A'\n",
    "                \n",
    "                data_table.add_row([row[sn_col], z, ra, dec])\n",
    "                found = True\n",
    "                break\n",
    "    \n",
    "    if found == False:\n",
    "        print('Could not find', row[sn_col], flush = True)\n",
    "\n",
    "data_table.write('OSE Data Table.csv', format = 'ascii.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
